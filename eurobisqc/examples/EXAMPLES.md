Reorganize examples (They are all in eurobisqc/test, should move to eurobisqc/examples):

# Example files and their purpose:

## Prerequisites

All the examples require access to the necessary python libraries. These are indicated in the installation instructions in README.md.
Furthermore, all the examples need access to the internet to call the following APIs:

1. pyxylookup for verification of the distance from shore and the depth of the observations
2. the IMIS web service to retrieve dataset characteristics like the geographical area.

The examples also need to access the local WORMS and Lookup databases, used to verify the presence of Weight, Size, Count
values and their correct use as well as sex values and their correct use. The Lookup database is also used to verify the
presence of the required fields and BasisofRecord.

---

## DwCA File Processing

The DwCA File processing examples DO NOT alter the data files. They calculate the QC mask by using the record being observed and all the dependent record recursively. QC masks are calculated for event and occurrence records. At the base of these files there is the function **dwca_file_labeling**, which can be found in **dwca_example_pipeline**. It takes a filename, which should be a DwCA zipped archive file, and a boolean that indicates whether the function shall emit log messages or not. If the log messages are activated, all the records shall be logged, and the QC mask shall be expanded to the human readable form generated by the method **decode_mask** of the QCFlag class in qcflags.py.

This uses the library **DwCAProcessor to process the DwCA file**. As in some cases the inter-dependencies between the eMoF records and the occurrence records are not captured by the library, an additional structure, acting as an index, has been created for this purpose.

File processing is faster than dataset processing, because the value is not written back to the files. (the library DWCA Processor does not support writing) However, in order to support this function, it would be sufficient to :

1. Write the event and occurrence records as they are processed and as QC is calculated
2. Add the "qc" field to the metadata (description) of occurrence and event records
3. grab the eMoF record set as it is on the original dataset, as they are not altered.
4. Close the files and produce a zip with the same name.

### Running DwCA File Processing 

In order to call this function on an example DwCA archive, the file **run_dwca_pipeline.py** has been provided. This contains a call to a simple graphical chooser, to use it select the directory where the archives are located and click OK, then enter the directory and click ok to select it. The files shall be listed in the list box, select one of those to process and click OK on the main window. The processing is verbose and shall show all the records being computed.

Another example is provided in **run_dwca_multiprocess.py**, in this one a folder browser is popped up to select the directory, then all files in the directory are partitioned among the cores, with this criteria: If there are at least three cores, then two are not user and the rest is divided using a multiprocessing Pool. If the cores are 2 or less, then only one process will be part of the pool (no actual multiprocessing will happen). The list of files contained in the selected directory is then split between the number of allocated cores that proceed to the calculation of the QC values. No intelligent load balancing is performed, so it is well possible that one process is assigned all files of a limited size while another will receive all files of a much bigger size. In that case, the first process will terminate much earlier than the second.

---

## Dataset Processing

The Dataset processing work on the EUROBIS database and **DO** update the QC bitmasks of the datasets being updated. (In fact, the biggest time eater is the database update).

The core of the processing (processes one dataset) is **dataset_qc_labeling** in mssql_example_pipeline.py. 
Everything necessary to process a dataset or to process a list of datasets in a multiprocessing fashion as explained above.

The starting point for **dataset_qc_labeling** is a dataset id, from which the records and the characteristics of the dataset 
are retrieved. 
The core of the dataset processing is a class called **EurobisDataset** contained in **eurobis_dataset.py**. 
It reproduces the same capabilities of the DwCAProcessor seen above, but starting from a dataset stored across several tables 
in a MS SQL database. However, no optimization techniques are used to limit memory usage 
(like processing the records in pages of XXX records at the time).

### Running Dataset Processing
**run_mssql_pipeline** runs a graphical dataset chooser that reports the id and display name for the full list of 
datasets contained in the database or in alternative, the list of datasets that contain at least a record with label 0 or NULL. 
Therefore to perform re-labeling of a dataset it is sufficient to set one of this dataset's records QC mask to NULL or 0. 
If a single dataset is selected, then the simple dataset labelling function **dataset_qc_labeling** is called. 
As the listbox is capable of multiple selections, if this is the case, then the **do_db_multi_selection** function is called, 
which performs multiprocessing in the same way described above, with the exception that a boolean parameter **server_local** 
in the section **[SQLSERVERDB]**, configurable in "dbworks/resources/config.ini" when set to **True** reserves 
two additional cores to be used by the MS SQL Server (in practice the Pool will consist of two processes less if this parameter 
is set to True. 
However the MS SQL Server will try to use anyway all cores, so in fact a better choice is to run the processing on 
a different machine than the database server. 
**mssql_random_record** contains a reproduction to a call to **dataset_qc_labeling** but with important differences: 
1. The dataset is selected at random within all datasets having less than 10000 records 
2. From this dataset, it chooses a random **core** event and all dependant records, and calculates the QC.  


### Considerations

1) DwCA archive do NOT contain a QC flag, so their QC processing is useful only during the processing of the file. 
2) The 18 basic QCs are all used by the above explained examples and they have been extensively tested. 
3) The QC "pipelines" proposed are examples based on the discussions and emails between AF/SaFITS and BV/VLIZ. 
Alternative ways of processing the records may be implemented based on these examples. 
   


---